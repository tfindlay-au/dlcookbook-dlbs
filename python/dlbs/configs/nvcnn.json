{
  "parameters": {
    "nvcnn.launcher": {
      "val": "${DLBS_ROOT}/scripts/launchers/nvcnn.sh",
      "type": "str",
      "desc": "Path to a script that launches NVCNN benchmarks."
    },
    "nvcnn.python_path": {
      "val": "$('${DLBS_ROOT}/python/nvcnn_benchmarks' if ${exp.docker} is False else '/workspace/nvcnn_benchmarks')$",
      "type": "str",
      "desc": "Path to a NVCNN benchmarks python folder. Depends on if bare metal/docker based benchmark is requested."
    },
    "nvcnn.env": {
      "val": [
        "PYTHONPATH=${nvcnn.python_path}:\\$PYTHONPATH",
        "${runtime.EXPORT_CUDA_CACHE_PATH}",
        "${runtime.EXPORT_CUDA_VISIBLE_DEVICES}"
      ],
      "type": "str",
      "desc": "Environmental variables to set for NVCNN benchmarks."
    },
    "nvcnn.data_dir": {
      "val": "",
      "type": "str",
      "desc": [
        "Path to dataset in TFRecord format (aka Example protobufs). Files should be named 'train-*' and 'validation-*'."
      ]
    },
    "nvcnn.display_every": {
      "val": 1000,
      "type": "int",
      "desc": "How often (in iterations) to print out running information."
    },
    "nvcnn.log_dir": {
      "val": "",
      "type": "str",
      "desc": "Directory in which to write training summaries and checkpoints."
    },
    "nvcnn.use_nccl": {
      "val": true,
      "type": "bool",
      "desc": "This is a 'nccl' parameter for nvcnn. See nvcnn.py for more details."
    },
    "nvcnn.use_xla": {
      "val": false,
      "type": "bool",
      "desc": "Enable/disable TensorFlow XLA optimizations."
    },
    "nvcnn.use_distort_color": {
      "val": false,
      "type": "bool",
      "desc": "Enable/disable distort colors."
    },
    "nvcnn.args": {
      "val": [
        "--model=${exp.model}",
        "$('' if not '${nvcnn.data_dir}' else '--data_dir=${nvcnn.data_dir}' if ${exp.docker} is False else '--data_dir=/workspace/data')$",
        "--batch_size=${exp.replica_batch}",
        "--nstep_burnin=${exp.num_warmup_batches}",
        "--num_batches=${exp.num_batches}",
        "$('--nccl' if ${nvcnn.use_nccl} else '--nonccl')$",
        "$('--xla' if ${nvcnn.use_xla} else '--noxla')$",
        "$('--distort_color' if ${nvcnn.use_distort_color} else '--nodistort_color')$",
        "--num_gpus=$(${exp.num_local_gpus} if '${exp.device_type}' == 'gpu' else 1)$",
        "--display_every=${nvcnn.display_every}",
        "--log_dir=${nvcnn.log_dir}",
        "$('--fp16' if '${exp.dtype}' == 'float16' else '')$"
      ],
      "type": "str",
      "desc": "These are a command line arguments passed to nvcnn_benchmarks script."
    },
    "nvcnn.docker_image": {
      "val": "hpe/tensorflow:cuda9-cudnn7",
      "type": "str",
      "desc": "The name of a docker image to use for NVCNN (TensorFlow) if containerized benchmark is requested."
    },
    "nvcnn.docker_args": {
      "val": [
        "-i",
        "--security-opt seccomp=unconfined",
        "--pid=host",
        "--volume=${DLBS_ROOT}/python/nvcnn_benchmarks:/workspace/nvcnn_benchmarks",
        "$('--volume=${runtime.cuda_cache}:/workspace/cuda_cache' if '${runtime.cuda_cache}' else '')$",
        "$('--volume=${nvcnn.data_dir}:/workspace/data' if '${nvcnn.data_dir}' else '')$",
        "$('--volume=${monitor.pid_folder}:/workspace/tmp' if ${monitor.frequency} > 0 else '')$",
        "${exp.docker_args}",
        "${nvcnn.docker_image}"
      ],
      "type": "str",
      "desc": "In case if containerized benchmarks, this are the docker parameters."
    },
    "nvcnn.host_libpath": {
      "val": "",
      "type": "str",
      "desc": "Basically, it's a LD_LIBRARY_PATH for NVCNN (TensorFlow) in case of a bare metal run."
    }
  },
  "extensions": [
    {
      "condition":{ "exp.framework": "nvcnn", "exp.docker": false },
      "parameters": { "nvcnn.env": [
        "PYTHONPATH=${nvcnn.python_path}:\\$PYTHONPATH",
        "${runtime.EXPORT_CUDA_CACHE_PATH}",
        "$('CUDA_CACHE_DISABLE=0' if '${runtime.cuda_cache}' else '')$",
        "$('CUDA_CACHE_MAXSIZE=2147483648' if '${runtime.cuda_cache}' else '')$",
        "${runtime.EXPORT_CUDA_VISIBLE_DEVICES}",
        "LD_LIBRARY_PATH=$('${nvcnn.host_libpath}:\\$LD_LIBRARY_PATH'.strip(' \t:'))$"
      ]}
    }
  ]
}
